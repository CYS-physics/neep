{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discrete flashing ratchet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from scipy import stats\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from misc.sampler import CartesianSampler\n",
    "# TODO\n",
    "# from toy.bead_spring import del_medium_etpy, del_shannon_etpy, simulation\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NEEP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NEEP(nn.Module):\n",
    "    def __init__(self, opt):\n",
    "        super(NEEP, self).__init__()\n",
    "        self.encoder = nn.Embedding(opt.n_token, opt.n_hidden)\n",
    "        self.h = nn.Sequential()\n",
    "        for i in range(opt.n_layer-1):\n",
    "            self.h.add_module('fc%d' % (i+1), nn.Linear(2*opt.n_hidden, 2*opt.n_hidden))\n",
    "            self.h.add_module('relu%d' % (i+1), nn.ReLU())\n",
    "        self.h.add_module('out', nn.Linear(2*opt.n_hidden, 1))\n",
    "\n",
    "    def forward(self, s1, s2):\n",
    "        s1 = self.encoder(s1)\n",
    "        s2 = self.encoder(s2)\n",
    "        x = torch.cat([s1, s2], dim=-1)\n",
    "        _x = torch.cat([s2, s1], dim=-1)\n",
    "        return self.h(x) - self.h(_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(opt, model, optim, trajs, sampler):\n",
    "    model.train()\n",
    "    batch, next_batch = next(sampler)\n",
    "\n",
    "    s_prev = trajs[batch].to(opt.device)\n",
    "    s_next = trajs[next_batch].to(opt.device)\n",
    "    ent_production = model(s_prev, s_next)\n",
    "    optim.zero_grad()\n",
    "    \n",
    "    # The objective function J. Equation (2)\n",
    "    loss = (-ent_production + torch.exp(-ent_production)).mean()\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "    return loss.item()\n",
    "\n",
    "\n",
    "def validate(opt, model, trajs, sampler):\n",
    "    model.eval()\n",
    "\n",
    "    ret = []\n",
    "    loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch, next_batch in sampler:\n",
    "            s_prev = trajs[batch].to(opt.device)\n",
    "            s_next = trajs[next_batch].to(opt.device)\n",
    "            \n",
    "            ent_production = model(s_prev, s_next)\n",
    "            entropy = ent_production.cpu().squeeze().numpy()\n",
    "            ret.append(entropy)\n",
    "            loss += (- ent_production + torch.exp(-ent_production)).sum().cpu().item()\n",
    "    loss = loss / sampler.size\n",
    "    ret = np.concatenate(ret)\n",
    "    ret = ret.reshape(trajs.shape[0], trajs.shape[1]-1)\n",
    "    return ret, loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fb9c0b1cb70>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt = Namespace()\n",
    "opt.device = 'cuda:0' \n",
    "opt.batch_size = 4096\n",
    "opt.test_batch_size = 50000\n",
    "opt.n_token = 6\n",
    "opt.n_hidden = 512\n",
    "\n",
    "opt.lr = 0.0001\n",
    "opt.wd = 5e-5\n",
    "\n",
    "opt.record_freq = 1000\n",
    "opt.seed = 398\n",
    "\n",
    "torch.manual_seed(opt.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trajectory sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1. 10.]\n",
      "MultiBead Simulation Starts with seed= 0\n",
      "[ 1. 10.]\n",
      "MultiBead Simulation Starts with seed= 1\n"
     ]
    }
   ],
   "source": [
    "opt.M = 1000          # number of trajectories\n",
    "opt.L = 10000         # lenth of a trjectory \n",
    "opt.V = 1             # potential \n",
    "\n",
    "trajs = simulation(opt.M, opt.L, opt.V, seed=0)\n",
    "test_trajs = simulation(opt.M, opt.L, opt.V, seed=1)\n",
    "\n",
    "trajs_t = torch.from_numpy(trajs).float()\n",
    "test_trajs_t = torch.from_numpy(test_trajs).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build model & Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NEEP(opt)\n",
    "model = model.to(opt.device)\n",
    "optim = torch.optim.Adam(model.parameters(), opt.lr, weight_decay=opt.wd)\n",
    "\n",
    "train_sampler = CartesianSampler(opt.M, opt.L, opt.batch_size, device=opt.device)\n",
    "test_sampler = CartesianSampler(opt.M, opt.L, opt.test_batch_size, device=opt.device, train=False)\n",
    "\n",
    "# NEEP outputs before training begin\n",
    "preds_untrained, _ = validate(opt, model, test_trajs_t, test_sampler)\n",
    "\n",
    "# Analytic EP\n",
    "ents = del_medium_etpy(test_trajs[:2], 1, 10) + del_shannon_etpy(test_trajs[:2], 1, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scatter(pred, ent):\n",
    "    pred_rate, _, r_value, pvalue, _  = stats.linregress(ent, pred)\n",
    "    plt.figure(figsize=(4,4), dpi=100)\n",
    "    sns.regplot(ent, pred,\n",
    "                color='C3', \n",
    "                line_kws={\n",
    "                    'lw':1.5,\n",
    "                    'label':'$R^2=%.4f$ p-value: %.4f' %(r_value**2, pvalue)},\n",
    "                scatter_kws={\n",
    "                    'color':'grey', \n",
    "                    'alpha':0.3, \n",
    "                    's':3, \n",
    "                    'rasterized':True})\n",
    "    plt.xlabel('$\\Delta S$', fontsize=12)\n",
    "    plt.ylabel('$\\Delta S_{\\\\theta}$', fontsize=12)\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3505098b6c074749b9d1d75beb239eb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "opt.n_iter = 10000 # number of training iteration\n",
    "\n",
    "for i in tqdm(range(1, opt.n_iter + 1)):\n",
    "    train(opt, model, optim, trajs_t, train_sampler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds, _ = validate(opt, model, test_trajs_t, test_sampler)\n",
    "\n",
    "# Analytic EP\n",
    "ents = del_medium_etpy(test_trajs[:100], opt.Tc, opt.Th) + del_shannon_etpy(test_trajs[:100], opt.Tc, opt.Th)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "### Entropy production (EP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single trajectory EP & Ensemble average EP"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neep",
   "language": "python",
   "name": "neep"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}